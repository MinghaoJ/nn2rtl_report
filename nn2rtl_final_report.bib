%% This BibTeX bibliography file was created using BibDesk.
%% https://bibdesk.sourceforge.io/

%% Created for Minghao Ji at 2019-02-16 20:35:30 -0500 


%% Saved with string encoding Unicode (UTF-8) 



@inproceedings{Ma2017Optimizing-Loop,
	Acmid = {3021736},
	Address = {New York, NY, USA},
	Author = {Ma, Yufei and Cao, Yu and Vrudhula, Sarma and Seo, Jae-sun},
	Booktitle = {Proceedings of the 2017 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays},
	Date-Added = {2019-02-16 20:25:46 -0500},
	Date-Modified = {2019-02-16 20:25:48 -0500},
	Doi = {10.1145/3020078.3021736},
	Isbn = {978-1-4503-4354-1},
	Keywords = {FPGA, convolutional neural networks, hardware acceleration},
	Location = {Monterey, California, USA},
	Numpages = {10},
	Pages = {45--54},
	Publisher = {ACM},
	Series = {FPGA '17},
	Title = {Optimizing Loop Operation and Dataflow in {FPGA} Acceleration of Deep Convolutional Neural Networks},
	Url = {http://doi.acm.org/10.1145/3020078.3021736},
	Year = {2017},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/3020078.3021736},
	Bdsk-Url-2 = {https://doi.org/10.1145/3020078.3021736}}

@article{Ucar2017Object-recognit,
	Abstract = { Autonomous driving requires reliable and accurate detection and recognition of surrounding objects in real drivable environments. Although different object detection algorithms have been proposed, not all are robust enough to detect and recognize occluded or truncated objects. In this paper, we propose a novel hybrid Local Multiple system (LM-CNN-SVM) based on Convolutional Neural Networks (CNNs) and Support Vector Machines (SVMs) due to their powerful feature extraction capability and robust classification property, respectively. In the proposed system, we divide first the whole image into local regions and employ multiple CNNs to learn local object features. Secondly, we select discriminative features by using Principal Component Analysis. We then import into multiple SVMs applying both empirical and structural risk minimization instead of using a direct CNN to increase the generalization ability of the classifier system. Finally, we fuse SVM outputs. In addition, we use the pre-trained AlexNet and a new CNN architecture. We carry out object recognition and pedestrian detection experiments on the Caltech-101 and Caltech Pedestrian datasets. Comparisons to the best state-of-the-art methods show that the proposed system achieved better results. },
	Author = {Ay{\c s}eg{\"u}l U{\c c}ar and Yakup Demir and C{\"u}neyt G{\"u}zeli{\c s}},
	Date-Added = {2019-02-16 20:24:21 -0500},
	Date-Modified = {2019-02-16 20:24:23 -0500},
	Doi = {10.1177/0037549717709932},
	Eprint = {https://doi.org/10.1177/0037549717709932},
	Journal = {SIMULATION},
	Number = {9},
	Pages = {759-769},
	Title = {Object recognition and detection with deep learning for autonomous driving applications},
	Url = {https://doi.org/10.1177/0037549717709932},
	Volume = {93},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1177/0037549717709932}}

@inproceedings{Cong2014Minimizing-Comp,
	Abstract = {Convolutional Neural Networks (CNNs) have been successfully used for many computer vision applications. It would be beneficial to these applications if the computational workload of CNNs could be reduced. In this work we analyze the linear algebraic properties of CNNs and propose an algorithmic modification to reduce their computational workload. An up to a 47{\%} reduction can be achieved without any change in the image recognition results or the addition of any hardware accelerators.},
	Address = {Cham},
	Author = {Cong, Jason and Xiao, Bingjun},
	Booktitle = {Artificial Neural Networks and Machine Learning -- ICANN 2014},
	Date-Added = {2019-02-16 20:23:26 -0500},
	Date-Modified = {2019-02-16 20:23:29 -0500},
	Isbn = {978-3-319-11179-7},
	Pages = {281--290},
	Publisher = {Springer International Publishing},
	Title = {Minimizing Computation in Convolutional Neural Networks},
	Year = {2014}}

@article{Krizhevsky2017ImageNet-Classi,
	Acmid = {3065386},
	Address = {New York, NY, USA},
	Author = {Krizhevsky, Alex and Sutskever, Ilya and Hinton, Geoffrey E.},
	Date-Added = {2019-02-16 20:22:08 -0500},
	Date-Modified = {2019-02-16 20:22:10 -0500},
	Doi = {10.1145/3065386},
	Issn = {0001-0782},
	Issue_Date = {June 2017},
	Journal = {Commun. ACM},
	Month = may,
	Number = {6},
	Numpages = {7},
	Pages = {84--90},
	Publisher = {ACM},
	Title = {Image{N}et Classification with Deep Convolutional Neural Networks},
	Url = {http://doi.acm.org/10.1145/3065386},
	Volume = {60},
	Year = {2017},
	Bdsk-Url-1 = {http://doi.acm.org/10.1145/3065386},
	Bdsk-Url-2 = {https://doi.org/10.1145/3065386}}

@article{Abdelouahab2017Hardware-Automa,
	Archiveprefix = {arXiv},
	Author = {Kamel Abdelouahab and Maxime Pelcat and Jocelyn Serot and Cedric Bourrasset and Jean-Charles Quinton and Fran{\c c}ois Berry},
	Date-Added = {2019-02-16 20:21:08 -0500},
	Date-Modified = {2019-02-16 20:35:18 -0500},
	Eprint = {1705.04543},
	Primaryclass = {cs.OH},
	Title = {Hardware Automated Dataflow Deployment of {CNN}s},
	Year = {2017}}

@article{Howard2017MobileNets:-Eff,
	Archiveprefix = {arXiv},
	Author = {Andrew G. Howard and Menglong Zhu and Bo Chen and Dmitry Kalenichenko and Weijun Wang and Tobias Weyand and Marco Andreetto and Hartwig Adam},
	Date-Added = {2019-02-16 20:19:55 -0500},
	Date-Modified = {2019-02-16 20:35:29 -0500},
	Eprint = {1704.04861},
	Primaryclass = {cs.CV},
	Title = {Mobile{N}ets: Efficient Convolutional Neural Networks for Mobile Vision Applications},
	Year = {2017}}

@article{Chen2018DeepLab:-Semant,
	Author = {L. {Chen} and G. {Papandreou} and I. {Kokkinos} and K. {Murphy} and A. L. {Yuille}},
	Date-Added = {2019-02-16 20:13:00 -0500},
	Date-Modified = {2019-02-16 20:13:06 -0500},
	Doi = {10.1109/TPAMI.2017.2699184},
	Issn = {0162-8828},
	Journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	Keywords = {convolution;feature extraction;feedforward neural nets;image segmentation;learning (artificial intelligence);random processes;highlight convolution;atrous convolution;Deep Convolutional Neural Networks;atrous spatial pyramid pooling;image context;fully connected Conditional Random Field;PASCAL VOC-2012 semantic image segmentation task;deep convolutional nets;Deep Learning;DeepLab;semantic image segmentation;probabilistic graphical models;Convolution;Image segmentation;Semantics;Image resolution;Computational modeling;Neural networks;Context;Convolutional neural networks;semantic segmentation;atrous convolution;conditional random fields},
	Month = {4},
	Number = {4},
	Pages = {834-848},
	Title = {Deep{L}ab: Semantic Image Segmentation with Deep Convolutional Nets, Atrous Convolution, and Fully Connected {CRF}s},
	Volume = {40},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1109/TPAMI.2017.2699184}}

@inproceedings{Ma2017An-automatic-RT,
	Author = {Y. {Ma} and Y. {Cao} and S. {Vrudhula} and J. {Seo}},
	Booktitle = {2017 27th International Conference on Field Programmable Logic and Applications (FPL)},
	Date-Added = {2019-02-16 20:10:35 -0500},
	Date-Modified = {2019-02-16 20:10:57 -0500},
	Doi = {10.23919/FPL.2017.8056824},
	Issn = {1946-1488},
	Keywords = {field programmable gate arrays;neural nets;program compilers;automatic RTL compiler;FPGA implementation;diverse deep convolutional neural networks;CNN model;RTL-level CNN compiler;FPGA hardware;inference tasks;low-level hardware optimization;general-purpose library;RTL modules;RTL level;directed acyclic graph;layer-by-layer sequential computation;end-to-end FPGA;ResNet-50;ResNet-152;automated compilation;CNN algorithm;FPGA accelerators;Stratix V FPGA;Arria 10 FPGA},
	Month = {9},
	Pages = {1-8},
	Title = {An automatic {RTL} compiler for high-throughput {FPGA} implementation of diverse deep convolutional neural networks},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.23919/FPL.2017.8056824}}

@article{Cheng2018Model-Compressi,
	Author = {Y. {Cheng} and D. {Wang} and P. {Zhou} and T. {Zhang}},
	Date-Added = {2019-02-16 20:05:24 -0500},
	Date-Modified = {2019-02-16 20:07:14 -0500},
	Doi = {10.1109/MSP.2017.2765695},
	Issn = {1053-5888},
	Journal = {IEEE Signal Processing Magazine},
	Keywords = {data compression;graphics processing units;image coding;neural nets;compression model;acceleration model;deep neural network;DNN;graphics processing unit;GPU;2012 ImageNet Challenge;convolutional layer;NVIDIA K40 machine;face-verification;labeled faces in the wild data set;LFW data set;Convolution;Training data;Neural networks;Quantization (signal);Convolutional codes;Computational modeling;Machine learning},
	Month = {1},
	Number = {1},
	Pages = {126-136},
	Title = {Model Compression and Acceleration for Deep Neural Networks: The Principles, Progress, and Challenges},
	Volume = {35},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1109/MSP.2017.2765695}}

@inproceedings{Sheng2018A-Quantization-,
	Author = {T. {Sheng} and C. {Feng} and S. {Zhuo} and X. {Zhang} and L. {Shen} and M. {Aleksic}},
	Booktitle = {2018 1st Workshop on Energy Efficient Machine Learning and Cognitive Computing for Embedded Applications (EMC2)},
	Date-Added = {2019-02-16 19:59:12 -0500},
	Date-Modified = {2019-02-16 20:09:26 -0500},
	Doi = {10.1109/EMC2.2018.00011},
	Keywords = {convolution;fixed point arithmetic;image classification;Internet of Things;learning (artificial intelligence);microprocessor chips;pipeline processing;quantisation (signal);MobileNets;deep learning;inference computation;mobile/IoT devices;network pruning;parameter compression;fixed-point pipeline;quantized models;float point models;quantization loss;quantization-friendly separable convolution architecture;float pipeline;networks design;MobileNetV1 model;Quantization (signal);Convolution;Pipelines;Mathematical model;Computational modeling;Standards;Training;Separable Convolution MobileNetV1 Quantization Fixed-point Inference},
	Month = {3},
	Pages = {14-18},
	Title = {A Quantization-Friendly Separable Convolution for {M}obile{N}ets},
	Year = {2018},
	Bdsk-Url-1 = {https://doi.org/10.1109/EMC2.2018.00011}}

@article{Chen2019Importance-Awar,
	Author = {B. {Chen} and C. {Gong} and J. {Yang}},
	Date-Added = {2019-02-16 19:10:04 -0500},
	Date-Modified = {2019-02-16 19:41:14 -0500},
	Doi = {10.1109/TITS.2018.2801309},
	Issn = {1524-9050},
	Journal = {IEEE Transactions on Intelligent Transportation Systems},
	Keywords = {automobiles;image classification;image segmentation;intelligent transportation systems;learning (artificial intelligence);mobile robots;neural nets;object recognition;road safety;robot vision;importance-aware semantic segmentation;autonomous driving system;safe driving;importance-aware loss;IAL;intelligent driving system;deep neural networks;deep learning models;FCN;SegNet;ENet;ERFNet;CamVid data set;Cityscapes data set;Image segmentation;Autonomous vehicles;Roads;Neural networks;Feature extraction;Semantics;Reliability;Semantic segmentation;importance-aware loss;deep leaning;autonomous driving},
	Month = {1},
	Number = {1},
	Pages = {137-148},
	Title = {Importance-Aware Semantic Segmentation for Autonomous Vehicles},
	Volume = {20},
	Year = {2019},
	Bdsk-Url-1 = {https://doi.org/10.1109/TITS.2018.2801309}}

@inproceedings{Wang2017Data-centric-co,
	Author = {P. {Wang} and Z. {Liu} and H. {Wang} and D. {Wang}},
	Booktitle = {2017 International Joint Conference on Neural Networks (IJCNN)},
	Date-Added = {2019-02-16 19:05:10 -0500},
	Date-Modified = {2019-02-16 19:40:58 -0500},
	Doi = {10.1109/IJCNN.2017.7965846},
	Issn = {2161-4407},
	Keywords = {convolution;neural nets;data-centric computation mode;deep convolutional neural network;CNN based methods;data transmission;data throughput;convolution operation;convolution processing period;on-chip memory hierarchy;Convolution;Hardware;System-on-chip;Engines;Neural networks;Data transfer;Neurons},
	Month = {5},
	Pages = {133-139},
	Title = {Data-centric computation mode for convolution in deep neural networks},
	Year = {2017},
	Bdsk-Url-1 = {https://doi.org/10.1109/IJCNN.2017.7965846}}

@electronic{Google-Inc.2018A-Tool-Develope,
	Author = {{Google Inc.}},
	Date-Added = {2019-02-16 19:02:03 -0500},
	Date-Modified = {2019-02-16 19:54:11 -0500},
	Month = {05},
	Title = {A Tool Developer's Guide to {T}ensor{F}low Model Files},
	Url = {https://www.tensorflow.org/extend/tool_developers/},
	Year = {2018},
	Bdsk-Url-1 = {https://www.tensorflow.org/extend/tool_developers/}}

@electronic{Intel-Corp.2018IntelR-ArriaR-1,
	Author = {{Intel Corp.}},
	Date-Added = {2019-02-16 19:00:32 -0500},
	Date-Modified = {2019-02-16 19:50:53 -0500},
	Month = {06},
	Title = {Intel{\textregistered} {A}rria{\textregistered} 10 Device Datasheet},
	Url = {https://www.altera.com/en_US/pdfs/literature/hb/arria-10/a10_datasheet.pdf},
	Year = {2018},
	Bdsk-Url-1 = {https://www.altera.com/en_US/pdfs/literature/hb/arria-10/a10_datasheet.pdf}}

@electronic{Google-Inc.2018TensorFlow-API-,
	Author = {{Google Inc.}},
	Date-Added = {2019-02-16 18:55:37 -0500},
	Date-Modified = {2019-02-16 19:54:27 -0500},
	Month = {05},
	Title = {Tensor{F}low {API} Documentation},
	Url = {https://www.tensorflow.org/api_docs/},
	Year = {2018},
	Bdsk-Url-1 = {https://www.tensorflow.org/api_docs/}}

@article{Stoimenov2016Face-recognitio,
	Author = {Stoimenov, Stoimen and Tsenov, Georgi T. and Mladenov, Valeri M.},
	Date-Added = {2019-02-16 18:52:34 -0500},
	Date-Modified = {2019-02-16 19:52:39 -0500},
	Doi = {10.1109/neurel.2016.7800138},
	Isbn = {9781509015306},
	Journal = {2016 13th Symposium on Neural Networks and Applications (NEUREL)},
	Month = {11},
	Publisher = {IEEE},
	Title = {Face recognition system in {A}ndroid using neural networks},
	Url = {http://dx.doi.org/10.1109/NEUREL.2016.7800138},
	Year = {2016},
	Bdsk-Url-1 = {http://dx.doi.org/10.1109/NEUREL.2016.7800138},
	Bdsk-Url-2 = {http://dx.doi.org/10.1109/neurel.2016.7800138}}
